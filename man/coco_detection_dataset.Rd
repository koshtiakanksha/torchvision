% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dataset-coco.R
\name{coco_detection_dataset}
\alias{coco_detection_dataset}
\title{COCO Detection Dataset}
\usage{
coco_detection_dataset(
  root,
  train = TRUE,
  year = c("2017", "2016", "2014"),
  download = FALSE,
  transforms = NULL,
  target_transform = NULL
)
}
\arguments{
\item{root}{Root directory where the dataset is stored or will be downloaded to.}

\item{train}{Logical. If TRUE, loads the training split; otherwise, loads the validation split.}

\item{year}{Character. Dataset version year. One of \code{"2014"}, \code{"2016"}, or \code{"2017"}.}

\item{download}{Logical. If TRUE, downloads the dataset if it's not already present in the \code{root} directory.}

\item{transforms}{Optional transform function applied to the image.}

\item{target_transform}{Optional transform function applied to the target (labels, boxes, etc.).}
}
\value{
An R6 dataset object. Each item is a list with two elements:
\describe{
\item{image}{A 3D \code{torch_tensor} of shape \code{[C, H, W]} (channel-first).}
\item{target}{A list with:
\describe{
\item{boxes}{A matrix of bounding boxes in \code{[x1, y1, x2, y2]} format.}
\item{labels}{An integer vector of class labels.}
\item{area}{A numeric vector indicating the area of each object.}
\item{iscrowd}{An integer vector (0 or 1) indicating whether objects are crowds.}
\item{segmentation}{A list of segmentation polygons per object.}
}
}
}
}
\description{
Loads the MS COCO dataset for object detection and segmentation.
}
\details{
The returned image is in CHW format (channels, height, width), matching the torch convention.
The dataset supports loading object detection annotations such as bounding boxes, labels,
areas, crowd indicators, and segmentation masks from the official COCO annotations.
}
\examples{
\dontrun{
ds <- coco_detection_dataset(
  root = "~/data",
  train = FALSE,
  year = "2017",
  download = TRUE
)

sample <- ds[1]
image <- sample$image
target <- sample$target

# Convert image to uint8
image_uint8 <- image$mul(255)$clamp(0, 255)$to(dtype = torch::torch_uint8())

# Ensure bounding boxes are torch tensors
boxes <- if (!inherits(target$boxes, "torch_tensor")) {
  torch::torch_tensor(target$boxes, dtype = torch::torch_float())
} else {
  target$boxes
}

# Convert labels to character
labels <- as.character(torch::as_array(target$labels))

# Draw bounding boxes
output <- torchvision::draw_bounding_boxes(
  image = image_uint8,
  boxes = boxes,
  labels = labels
)

# Convert to array and plot
output_array <- as.array(output$permute(c(2, 3, 1)))  # CHW to HWC
output_array <- as.numeric(output_array) / 255
dim(output_array) <- dim(as.array(output$permute(c(2, 3, 1))))
plot(as.raster(output_array))
}
}
